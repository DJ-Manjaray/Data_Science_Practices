{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxQGRnz6+qW3K9NjBQg0L+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJ-Manjaray/Data_Science_Practices/blob/main/Comparing_randomized_search_and_grid_search_for_hyperparameter_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-D0M6Gt_YhqU"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get some data\n",
        "X, y = load_digits(return_X_y=True, n_class=3)\n",
        "\n",
        "# build a classifier\n",
        "clf = SGDClassifier(loss=\"hinge\", penalty=\"elasticnet\", fit_intercept=True)"
      ],
      "metadata": {
        "id": "Y757HcFzZIWZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\n",
        "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                    results[\"mean_test_score\"][candidate],\n",
        "                    results[\"std_test_score\"][candidate],\n",
        "                )\n",
        "            )\n",
        "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
        "            print(\"\")"
      ],
      "metadata": {
        "id": "18GS37r9ZKW-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify parameters and distributions to sample from\n",
        "param_dist = {\n",
        "    \"average\": [True, False],\n",
        "    \"l1_ratio\": stats.uniform(0, 1),\n",
        "    \"alpha\": stats.loguniform(1e-2, 1e0),\n",
        "}"
      ],
      "metadata": {
        "id": "tHnOSJH0ZNg_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run randomized search\n",
        "n_iter_search = 15\n",
        "random_search = RandomizedSearchCV(\n",
        "    clf, param_distributions=param_dist, n_iter=n_iter_search\n",
        ")"
      ],
      "metadata": {
        "id": "3nqgMaTSZPhY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "random_search.fit(X, y)\n",
        "print(\n",
        "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
        "    % ((time() - start), n_iter_search)\n",
        ")\n",
        "report(random_search.cv_results_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfeSaAMVZSN7",
        "outputId": "2b383d9b-8468-4a52-cdac-7eec6e580799"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomizedSearchCV took 1.37 seconds for 15 candidates parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.989 (std: 0.007)\n",
            "Parameters: {'alpha': 0.02796719275904662, 'average': False, 'l1_ratio': 0.32926885577193055}\n",
            "\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.989 (std: 0.015)\n",
            "Parameters: {'alpha': 0.02312119697425407, 'average': False, 'l1_ratio': 0.21912139452497004}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.987 (std: 0.007)\n",
            "Parameters: {'alpha': 0.14646129330815819, 'average': False, 'l1_ratio': 0.06890152076660849}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use a full grid over all parameters\n",
        "param_grid = {\n",
        "    \"average\": [True, False],\n",
        "    \"l1_ratio\": np.linspace(0, 1, num=10),\n",
        "    \"alpha\": np.power(10, np.arange(-2, 1, dtype=float)),\n",
        "}"
      ],
      "metadata": {
        "id": "zucTyqjiZVVG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
        "start = time()\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\n",
        "    \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "    % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
        ")\n",
        "report(grid_search.cv_results_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFkhOuzVZX8f",
        "outputId": "f60229b2-a5a1-45d8-f3c5-eb0f2c441f2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV took 2.76 seconds for 60 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.991 (std: 0.008)\n",
            "Parameters: {'alpha': 0.01, 'average': False, 'l1_ratio': 0.1111111111111111}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.991 (std: 0.006)\n",
            "Parameters: {'alpha': 0.01, 'average': False, 'l1_ratio': 0.0}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.991 (std: 0.010)\n",
            "Parameters: {'alpha': 0.1, 'average': False, 'l1_ratio': 0.1111111111111111}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.991 (std: 0.010)\n",
            "Parameters: {'alpha': 0.1, 'average': False, 'l1_ratio': 0.2222222222222222}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}